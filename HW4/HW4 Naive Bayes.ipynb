{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive_Bayes:\n",
    "    def __init__(self,smooth=0.5,path=\"./languageID/\"):\n",
    "        \n",
    "        # dictionary to count character occurances\n",
    "        alphabet = {\"a\":0, \"b\":0,\"c\":0, \"d\":0,\"e\":0,\"f\":0,\"g\":0, \"h\":0,\"i\":0, \"j\":0, \"k\":0, \"l\":0, \n",
    "                    \"m\":0, \"n\":0, \"o\":0, \"p\":0, \"q\":0, \"r\":0, \"r\":0, \"s\":0, \"t\":0, \"u\":0, \"v\":0, \n",
    "                    \"w\":0, \"x\":0, \"y\":0, \"z\":0, \" \": 0};\n",
    "        \n",
    "        self.lang = np.array(['e','s','j'])\n",
    "        self.prior = np.array([0,0,0]).astype('float')\n",
    "        self.alpha = [alphabet.copy(),alphabet.copy(),alphabet.copy()] # shallow copies\n",
    "        self.log_liklihood = [alphabet.copy(),alphabet.copy(),alphabet.copy()]\n",
    "        self.path = path\n",
    "        self.train = []\n",
    "        self.test = []\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def set_data(self,train_size=10):\n",
    "        assert train_size <= 20 # there are only 20 of each file\n",
    "        for lang in self.lang:\n",
    "            for i in range(train_size):\n",
    "                self.train.append(lang+str(i)+\".txt\")\n",
    "            for i in range(train_size,20):\n",
    "                self.test.append(lang+str(i)+\".txt\")\n",
    "                \n",
    "    def get_prior(self):\n",
    "        count_e = count_s = count_j = 0\n",
    "        assert len(self.train) > 0\n",
    "        for file in self.train:\n",
    "            if 'e' in file: # count occurances of english files\n",
    "                count_e += 1\n",
    "            elif 's' in file: # count occurances of spanish files\n",
    "                count_s += 1\n",
    "            elif 'j' in file: # count occurances of japanese files\n",
    "                count_j += 1\n",
    "        tot = count_e + count_s + count_j + (3*self.smooth) # total files with smoothing factor added\n",
    "        self.prior[0] = (1.0*count_e+self.smooth)/tot\n",
    "        self.prior[1] = (1.0*count_s+self.smooth)/tot\n",
    "        self.prior[2] = (1.0*count_j+self.smooth)/tot\n",
    "        \n",
    "    def print_prior(self):\n",
    "        print(\"P(Y=english) = %f   P(Y=spanish) = %f   P(Y=japanese) = %f\" %(self.prior[0],self.prior[1],self.prior[2]))\n",
    "    \n",
    "    def get_cond_prob(self):\n",
    "        assert len(self.train) > 0\n",
    "        for file in self.train:\n",
    "            i = np.argwhere(file[0] == self.lang)[0][0] # checks the language of the file\n",
    "            text = open(self.path+file,'r') # open file to read\n",
    "            for r in text: # iterate over rows\n",
    "                for c in r: # iterate over characters\n",
    "                    if (c == '\\n'): # skip newline\n",
    "                        continue\n",
    "                    self.alpha[i][c] += 1 # increment count of current character\n",
    "        for i in range(len(self.lang)):\n",
    "            tot = sum(self.alpha[i].values()) + (27*self.smooth)\n",
    "            for key in self.alpha[i].keys():\n",
    "                self.alpha[i][key] += self.smooth\n",
    "                self.alpha[i][key] /= tot # normalize character counts\n",
    "                self.log_liklihood[i][key] = np.log10(self.alpha[i][key])\n",
    "                \n",
    "    def get_count(self,filename):\n",
    "        temp_alpha = {\"a\":0, \"b\":0,\"c\":0, \"d\":0,\"e\":0,\"f\":0,\"g\":0, \"h\":0,\"i\":0, \"j\":0, \"k\":0, \"l\":0, \n",
    "                    \"m\":0, \"n\":0, \"o\":0, \"p\":0, \"q\":0, \"r\":0, \"r\":0, \"s\":0, \"t\":0, \"u\":0, \"v\":0, \n",
    "                    \"w\":0, \"x\":0, \"y\":0, \"z\":0, \" \": 0};\n",
    "        try:\n",
    "            text = open(self.path+filename,'r')\n",
    "            for r in text:\n",
    "                for c in r:\n",
    "                    if (c== '\\n'):\n",
    "                        continue\n",
    "                    temp_alpha[c] += 1\n",
    "        except:\n",
    "            print(\"error opening file\")\n",
    "        return temp_alpha\n",
    "    \n",
    "    def get_prob(self,counts):\n",
    "        probs = np.zeros(3)\n",
    "        for l in range(len(self.lang)):\n",
    "            for key in counts.keys():\n",
    "                # probability is theta^count so log(probability) is count*theta\n",
    "                probs[l] += counts[key]*self.log_liklihood[l][key]\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Y=english) = 0.333333   P(Y=spanish) = 0.333333   P(Y=japanese) = 0.333333\n"
     ]
    }
   ],
   "source": [
    "## Problem 4.1\n",
    "\n",
    "nb = Naive_Bayes(smooth=0.5)\n",
    "nb.set_data(train_size=10)\n",
    "nb.get_prior()\n",
    "nb.print_prior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Probabilities for e \n",
      "\n",
      "\n",
      " Probabilities for s \n",
      "\n",
      "\n",
      " Probabilities for j \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Problem 4.2 and 4.3\n",
    "\n",
    "nb.get_cond_prob()\n",
    "for i in range(3):\n",
    "    print(\"\\n Probabilities for\",str(nb.lang[i]),'\\n')\n",
    "    for key,val in nb.alpha[i].items():\n",
    "        #print(\"%s: %f\" %(key,round(val,5))) # commented out to reduce clutter\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 4.4\n",
    "\n",
    "temp_count = nb.get_count(\"e10.txt\")\n",
    "for key,val in temp_count.items():\n",
    "    #print(\"%s:  %03d\" %(key,val)) # commented out to reduce clutter\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Probabilities are: [-3405.67889149 -3677.29386843 -3809.38498463]\n",
      "Predicted language is e\n"
     ]
    }
   ],
   "source": [
    "## Problem 4.5\n",
    "\n",
    "probs = nb.get_prob(temp_count)\n",
    "print(\"Log Probabilities are:\",probs)\n",
    "print(\"Predicted language is %s\" %(nb.lang[np.argmax(probs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.  0.  0.]\n",
      " [ 0. 10.  0.]\n",
      " [ 0.  0. 10.]]\n"
     ]
    }
   ],
   "source": [
    "## Problem 4.7\n",
    "\n",
    "conf = np.zeros((3,3))\n",
    "for col,lang in enumerate(nb.lang):\n",
    "    for i in range(10,20):\n",
    "        count = nb.get_count(str(lang)+str(i)+\".txt\")\n",
    "        probs = nb.get_prob(count)\n",
    "        row = np.argmax(probs)\n",
    "        conf[row,col] += 1\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Probabilities are: [-3405.67889149 -3677.29386843 -3809.38498463]\n"
     ]
    }
   ],
   "source": [
    "## Problem 4.8\n",
    "\n",
    "test_doc = \"e10.txt\"\n",
    "file = open(nb.path+test_doc)\n",
    "text = list(file.read())\n",
    "random.shuffle(text)\n",
    "scrambled = ''.join(text)\n",
    "file_scram = open(nb.path+\"scram_e10.txt\",'w')\n",
    "file_scram.write(scrambled)\n",
    "file_scram.close()\n",
    "scram_count = nb.get_count(\"scram_e10.txt\")\n",
    "scram_prob = nb.get_prob(scram_count)\n",
    "print(\"Log Probabilities are:\",scram_prob)\n",
    "# we see they are equal to the log probabilities from question 4.5\n",
    "# so shuffling/order does not matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
